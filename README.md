#DINO Self-Attention Visualizations

#This notebook visualizes the self-attention patterns of Vision Transformers (ViT) pre-trained using the DINO method. The DINO approach allows ViTs to segment objects within images without explicit training for segmentation, a behavior not observed in traditional convolutional models like ResNets.

Features
- Visualize self-attention maps in Vision Transformers.
- Explore how DINO enables object segmentation in images.
- Compare self-attention in ViTs to classical models like ResNets.
